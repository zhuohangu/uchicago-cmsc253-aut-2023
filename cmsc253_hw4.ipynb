{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la # matrix rank, inverse import scipy.io\n",
    "import matplotlib.pyplot as plt # plots\n",
    "import scipy.io as sio\n",
    "import sys\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1 Gram-Schmidt. <br>\n",
    "(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.13304645e-01, -5.43794290e-01,  1.99095308e-01,\n",
       "        -5.51132525e-02,  1.19578493e-02, -1.96870730e-03,\n",
       "        -2.10219152e-04],\n",
       "       [ 4.06652323e-01,  3.03317262e-01, -6.88560548e-01,\n",
       "         4.75965265e-01, -1.97392654e-01,  5.41151990e-02,\n",
       "         3.01288446e-03],\n",
       "       [ 2.71101548e-01,  3.93949644e-01, -2.07134626e-01,\n",
       "        -4.90111167e-01,  6.10839674e-01, -3.26893986e-01,\n",
       "         1.54577469e-02],\n",
       "       [ 2.03326161e-01,  3.81744394e-01,  1.12389156e-01,\n",
       "        -4.39598473e-01, -2.54179063e-01,  6.41045574e-01,\n",
       "        -2.08187091e-01],\n",
       "       [ 1.62660929e-01,  3.51412668e-01,  2.91518455e-01,\n",
       "        -1.12276608e-01, -4.99206689e-01, -2.02224426e-01,\n",
       "         6.15118567e-01],\n",
       "       [ 1.35550774e-01,  3.20235052e-01,  3.89191824e-01,\n",
       "         2.30886766e-01, -1.50594721e-01, -5.41817789e-01,\n",
       "        -7.06123659e-01],\n",
       "       [ 1.16186378e-01,  2.92095792e-01,  4.40744903e-01,\n",
       "         5.20623748e-01,  5.01273338e-01,  3.80535581e-01,\n",
       "         2.81830797e-01]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gram_schmidt(X):\n",
    "    # X is an n-by-p matrix.\n",
    "    # Returns U an orthonormal matrix.\n",
    "    # eps is a threshold value to identify if a vector # is nearly a zero vector.\n",
    "\n",
    "    eps = 1e-12\n",
    "\n",
    "    n, p = X.shape\n",
    "    U = np.zeros((n, 0))\n",
    "    for j in range(p):\n",
    "        # Get the j-th column of matrix X\n",
    "        v = X[:, j]\n",
    "        # Write your own code here: Perform the\n",
    "        # orthogonalization by subtracting the projections on\n",
    "        # all columns of U. And then check whether the vector\n",
    "        # you get is nearly a zero vector.\n",
    "        v = v - U@U.T@v\n",
    "        v = np.reshape(v, (-1, 1))        \n",
    "        if np.linalg.norm(v) > eps:\n",
    "            # Normalize vector v and append it to U\n",
    "            U = np.hstack((U, v / la.norm(v)))\n",
    "    return U\n",
    "X = np.array([[1, 1/2, 1/3, 1/4, 1/5, 1/6, 1/7],\n",
    "              [1/2, 1/3, 1/4, 1/5, 1/6, 1/7, 1/8],\n",
    "              [1/3, 1/4, 1/5, 1/6, 1/7, 1/8, 1/9],\n",
    "              [1/4, 1/5, 1/6, 1/7, 1/8, 1/9, 1/10],\n",
    "              [1/5, 1/6, 1/7, 1/8, 1/9, 1/10, 1/11],\n",
    "              [1/6, 1/7, 1/8, 1/9, 1/10, 1/11, 1/12],\n",
    "              [1/7, 1/8, 1/9, 1/10, 1/11, 1/12, 1/13]])\n",
    "gram_schmidt(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  6.73072709e-16 -2.36616282e-15  2.80331314e-14\n",
      "  -1.92849903e-12  1.25247715e-10 -9.71088800e-09]\n",
      " [ 6.73072709e-16  0.00000000e+00 -2.76723089e-14  3.71008779e-13\n",
      "  -2.63988831e-12 -4.05814549e-11  5.49175827e-09]\n",
      " [-2.36616282e-15 -2.76723089e-14  1.11022302e-16  8.52865001e-12\n",
      "  -2.31620473e-10  5.20528393e-09 -1.33284293e-07]\n",
      " [ 2.80331314e-14  3.71008779e-13  8.52865001e-12 -2.22044605e-16\n",
      "  -9.04092928e-09  4.29613409e-07 -1.80981921e-05]\n",
      " [-1.92849903e-12 -2.63988831e-12 -2.31620473e-10 -9.04092928e-09\n",
      "   0.00000000e+00  2.66371580e-05 -2.30322707e-03]\n",
      " [ 1.25247715e-10 -4.05814549e-11  5.20528393e-09  4.29613409e-07\n",
      "   2.66371580e-05  0.00000000e+00 -2.27098006e-01]\n",
      " [-9.71088800e-09  5.49175827e-09 -1.33284293e-07 -1.80981921e-05\n",
      "  -2.30322707e-03 -2.27098006e-01  1.11022302e-16]]\n",
      "L1 matrix norm is 0.22941947980869065\n"
     ]
    }
   ],
   "source": [
    "def hilbert_matrix(n):\n",
    "    X = np.array([[1.0 / (i + j - 1) for i in \\\n",
    "                   range(1, n + 1)] for j in range(1, n + 1)])\n",
    "    return X\n",
    "n = 7\n",
    "X = hilbert_matrix(n)\n",
    "U = gram_schmidt(X)\n",
    "L1 = np.identity((U.T@U).shape[0]) - U.T@U\n",
    "print(L1)\n",
    "err = la.norm(L1, ord=1)\n",
    "print(f'L1 matrix norm is {err}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  1.54737334e-15 -2.16146545e-14  3.62931907e-13\n",
      "  -7.97459321e-12  3.16995839e-10 -1.90386089e-08]\n",
      " [ 1.54737334e-15  0.00000000e+00  1.02695630e-15 -2.63955524e-14\n",
      "   9.00696184e-13 -2.74882339e-11  1.03917761e-09]\n",
      " [-2.16146545e-14  1.02695630e-15 -2.22044605e-16  3.05311332e-15\n",
      "  -2.71893619e-13  1.51737511e-11 -6.93317848e-10]\n",
      " [ 3.62931907e-13 -2.63955524e-14  3.05311332e-15  0.00000000e+00\n",
      "  -1.66533454e-15 -2.34368080e-13  4.83647289e-11]\n",
      " [-7.97459321e-12  9.00696184e-13 -2.71893619e-13 -1.66533454e-15\n",
      "   0.00000000e+00  2.01227923e-14 -2.16494878e-12]\n",
      " [ 3.16995839e-10 -2.74882339e-11  1.51737511e-11 -2.34368080e-13\n",
      "   2.01227923e-14  2.22044605e-16 -1.46549439e-14]\n",
      " [-1.90386089e-08  1.03917761e-09 -6.93317848e-10  4.83647289e-11\n",
      "  -2.16494878e-12 -1.46549439e-14 -2.22044605e-16]]\n",
      "Modified L1 matrix norm is 2.0821648873819987e-08\n"
     ]
    }
   ],
   "source": [
    "def modified_gram_schmidt(X):\n",
    "    # Define a threshold value to identify if a vector # is nearly a zero vector.\n",
    "    eps = 1e-12\n",
    "    n, p = X.shape\n",
    "    U = np.zeros((n, 0))\n",
    "    for j in range(p):\n",
    "        # Get the j-th column of matrix X\n",
    "        v = X[:, j]\n",
    "        for i in range(j):\n",
    "            # Compute and subtract the projection of\n",
    "            # vector v onto the i-th column of U\n",
    "            v = v - np.dot(U[:, i], v) * U[:, i]\n",
    "        v = np.reshape(v, (-1, 1))\n",
    "        # Check whether the vector we get is nearly # a zero vector\n",
    "        if np.linalg.norm(v) > eps:\n",
    "            # Normalize vector v and append it to U\n",
    "            U = np.hstack((U, v / la.norm(v)))\n",
    "    return U\n",
    "n = 7\n",
    "X = hilbert_matrix(n)\n",
    "U_modified = modified_gram_schmidt(X)\n",
    "L1_modified = np.identity((U_modified.T@U_modified).shape[0]) - \\\n",
    "    U_modified.T@U_modified\n",
    "\n",
    "L1_modified\n",
    "print(L1_modified)\n",
    "err_modified = la.norm(L1_modified, ord=1)\n",
    "print(f'Modified L1 matrix norm is {err_modified}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the traditional approach to Gram-Schmidt, each vector in the sequence is made orthogonal to all previously processed vectors by subtracting their projections. The modified Gram-Schmidt re-orthogonalizes each vector against all previously orthogonalized vectors, one at a time. This stepwise approach reduces the accumulation of errors and maintains better orthogonality. Therefore, the modified Gram-Schmidtis process is generally superior to the original process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 <br>\n",
    "(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error estimate: 0.16517857142857142\n"
     ]
    }
   ],
   "source": [
    "d = np.load(\"face_emotion_data.npz\")\n",
    "X = d['X']\n",
    "y = d['y']\n",
    "\n",
    "n, p = np.shape(X)\n",
    "\n",
    "# error rate for regularized least squares\n",
    "error_RLS = np.zeros((8, 7))\n",
    "# error rate for truncated SVD\n",
    "error_SVD = np.zeros((8, 7))\n",
    "\n",
    "# SVD parameters to test\n",
    "k_vals = np.arange(9) + 1\n",
    "param_err_SVD = np.zeros(len(k_vals))\n",
    "\n",
    "subset_count = 8\n",
    "sample_count, feature_count = X.shape\n",
    "subset_size = sample_count // subset_count\n",
    "# Reshape arrays for easier subset-level manipulation\n",
    "features = X.reshape(subset_count , subset_size ,feature_count)\n",
    "labels = y.reshape(subset_count , subset_size)\n",
    "train_set_size = (subset_count - 2) * subset_size\n",
    "\n",
    "for i in range(subset_count):\n",
    "    X = np.vstack((features[:i], features[i+1:]))\n",
    "    y = np.vstack((labels[:i], labels[i+1:]))\n",
    "    X_hold_out = features[i].reshape(subset_size, feature_count)\n",
    "    y_hold_out = labels[i].reshape(subset_size, 1)\n",
    "    for j in range(subset_count-1):\n",
    "        X_train = np.vstack((X[:j], X[j+1:]))\n",
    "        X_train = X_train.reshape(train_set_size, feature_count)\n",
    "        y_train = np.vstack((y[:j], y[j+1:]))\n",
    "        y_train = y_train.reshape(train_set_size, 1)\n",
    "\n",
    "        U, Sigma, VT = la.svd(X_train)\n",
    "\n",
    "        X_test = X[j].reshape(subset_size, feature_count)\n",
    "        y_test = y[j].reshape(subset_size, 1)\n",
    "\n",
    "        param_err_SVD = np.zeros(len(k_vals))\n",
    "        w_hat_lst = []\n",
    "\n",
    "        for k in k_vals:\n",
    "            Sigma_plus = np.zeros((len(VT), len(U)))\n",
    "            for l in range(k):\n",
    "                Sigma_plus[l][l] = 1/Sigma[l]\n",
    "            w_hat = VT.T@Sigma_plus@U.T@y_train\n",
    "            w_hat_lst.append(w_hat)\n",
    "            y_hat = X_test@w_hat\n",
    "\n",
    "            for s in range(subset_size):\n",
    "                if y_hat[s][0] <= 0 and y_test[s] == 1:\n",
    "                    param_err_SVD[k-1] += 1\n",
    "                if y_hat[j][0] >= 0 and y_test[s] == -1:\n",
    "                     param_err_SVD[k-1] += 1\n",
    "\n",
    "        k_best = np.argmin(param_err_SVD)\n",
    "        w_hat_best = w_hat_lst[k_best]\n",
    "\n",
    "        y_hat_hold_out = X_hold_out@w_hat_best\n",
    "        for z in range(subset_size):\n",
    "            if y_hat_hold_out[z][0] <= 0 and y_hold_out[z] == 1:\n",
    "                error_SVD[i][j] += 1\n",
    "            if y_hat_hold_out[z][0] >= 0 and y_hold_out[z] == -1:\n",
    "                error_SVD[i][j] += 1\n",
    "error_SVD = error_SVD/16\n",
    "print(f\"Error estimate: {np.mean(error_SVD)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error estimate: 0.23214285714285715\n"
     ]
    }
   ],
   "source": [
    "# X = d['X']\n",
    "# y = d['y']\n",
    "error_RLS = np.zeros((8, 7))\n",
    "\n",
    "# n, p = np.shape(X)\n",
    "# RLS parameters to test\n",
    "lambda_vals = np.array([0, 0.5, 1, 2, 4, 8, 16])\n",
    "param_err_RLS = np.zeros(len(lambda_vals))\n",
    "\n",
    "for i in range(subset_count):\n",
    "    X = np.vstack((features[:i], features[i+1:]))\n",
    "    y = np.vstack((labels[:i], labels[i+1:]))\n",
    "    X_hold_out = features[i].reshape(subset_size, feature_count)\n",
    "    y_hold_out = labels[i].reshape(subset_size, 1)\n",
    "    for j in range(subset_count-1):\n",
    "        X_train = np.vstack((X[:j], X[j+1:]))\n",
    "        X_train = X_train.reshape(train_set_size, feature_count)\n",
    "        y_train = np.vstack((y[:j], y[j+1:]))\n",
    "        y_train = y_train.reshape(train_set_size, 1)\n",
    "\n",
    "        X_test = X[j].reshape(subset_size, feature_count)\n",
    "        y_test = y[j].reshape(subset_size, 1)\n",
    "\n",
    "        param_err_RLS = np.zeros(len(k_vals))\n",
    "        w_hat_lst = []\n",
    "        \n",
    "        for idx, lmd in enumerate(lambda_vals):\n",
    "            w_hat = la.inv(X_train.T@X_train + lmd*np.identity(feature_count))\n",
    "            w_hat_lst.append(w_hat)\n",
    "            y_hat = X_test@w_hat\n",
    "\n",
    "            for s in range(subset_size):\n",
    "                if y_hat[s][0] <= 0 and y_test[s] == 1:\n",
    "                    param_err_RLS[k-1] += 1\n",
    "                if y_hat[j][0] >= 0 and y_test[s] == -1:\n",
    "                    param_err_RLS[k-1] += 1\n",
    "\n",
    "        k_best = np.argmin(param_err_RLS)\n",
    "        w_hat_best = w_hat_lst[k_best]\n",
    "\n",
    "        y_hat_hold_out = X_hold_out@w_hat_best\n",
    "        for z in range(subset_size):\n",
    "            if y_hat_hold_out[z][0] <= 0 and y_hold_out[z] == 1:\n",
    "                error_RLS[i][j] += 1\n",
    "            if y_hat_hold_out[z][0] >= 0 and y_hold_out[z] == -1:\n",
    "                error_RLS[i][j] += 1\n",
    "error_RLS = error_RLS/16\n",
    "print(f\"Error estimate: {np.mean(error_RLS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error estimate: 0.15959821428571427\n"
     ]
    }
   ],
   "source": [
    "X = d['X']\n",
    "y = d['y']\n",
    "new_features = X@np.random.rand(9,3)\n",
    "X_new = np.concatenate((X, new_features), axis = 1)\n",
    "\n",
    "### (a)' ###\n",
    "n, p = np.shape(X_new)\n",
    "\n",
    "# error rate for regularized least squares\n",
    "error_RLS = np.zeros((8, 7))\n",
    "# error rate for truncated SVD\n",
    "error_SVD = np.zeros((8, 7))\n",
    "\n",
    "# SVD parameters to test\n",
    "k_vals = np.arange(9) + 1\n",
    "param_err_SVD = np.zeros(len(k_vals))\n",
    "\n",
    "subset_count = 8\n",
    "sample_count, feature_count = X_new.shape\n",
    "subset_size = sample_count // subset_count\n",
    "# Reshape arrays for easier subset-level manipulation\n",
    "features = X_new.reshape(subset_count , subset_size, feature_count)\n",
    "labels = y.reshape(subset_count , subset_size)\n",
    "train_set_size = (subset_count - 2) * subset_size\n",
    "\n",
    "for i in range(subset_count):\n",
    "    X = np.vstack((features[:i], features[i+1:]))\n",
    "    y = np.vstack((labels[:i], labels[i+1:]))\n",
    "    X_hold_out = features[i].reshape(subset_size, feature_count)\n",
    "    y_hold_out = labels[i].reshape(subset_size, 1)\n",
    "    for j in range(subset_count-1):\n",
    "        X_train = np.vstack((X[:j], X[j+1:]))\n",
    "        X_train = X_train.reshape(train_set_size, feature_count)\n",
    "        y_train = np.vstack((y[:j], y[j+1:]))\n",
    "        y_train = y_train.reshape(train_set_size, 1)\n",
    "\n",
    "        U, Sigma, VT = la.svd(X_train)\n",
    "\n",
    "        X_test = X[j].reshape(subset_size, feature_count)\n",
    "        y_test = y[j].reshape(subset_size, 1)\n",
    "\n",
    "        param_err_SVD = np.zeros(len(k_vals))\n",
    "        w_hat_lst = []\n",
    "\n",
    "        for k in k_vals:\n",
    "            Sigma_plus = np.zeros((len(VT), len(U)))\n",
    "            for l in range(k):\n",
    "                Sigma_plus[l][l] = 1/Sigma[l]\n",
    "            w_hat = VT.T@Sigma_plus@U.T@y_train\n",
    "            w_hat_lst.append(w_hat)\n",
    "            y_hat = X_test@w_hat\n",
    "\n",
    "            for s in range(subset_size):\n",
    "                if y_hat[s][0] <= 0 and y_test[s] == 1:\n",
    "                    param_err_SVD[k-1] += 1\n",
    "                if y_hat[j][0] >= 0 and y_test[s] == -1:\n",
    "                     param_err_SVD[k-1] += 1\n",
    "\n",
    "        k_best = np.argmin(param_err_SVD)\n",
    "        w_hat_best = w_hat_lst[k_best]\n",
    "\n",
    "        y_hat_hold_out = X_hold_out@w_hat_best\n",
    "        for z in range(subset_size):\n",
    "            if y_hat_hold_out[z][0] <= 0 and y_hold_out[z] == 1:\n",
    "                error_SVD[i][j] += 1\n",
    "            if y_hat_hold_out[z][0] >= 0 and y_hold_out[z] == -1:\n",
    "                error_SVD[i][j] += 1\n",
    "error_SVD = error_SVD/16\n",
    "print(f\"Error estimate: {np.mean(error_SVD)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error estimate: 0.22879464285714285\n"
     ]
    }
   ],
   "source": [
    "### (b)' ###\n",
    "# RLS parameters to test\n",
    "lambda_vals = np.array([0, 0.5, 1, 2, 4, 8, 16])\n",
    "param_err_RLS = np.zeros(len(lambda_vals))\n",
    "\n",
    "error_RLS = np.zeros((8, 7))\n",
    "\n",
    "for i in range(subset_count):\n",
    "    X = np.vstack((features[:i], features[i+1:]))\n",
    "    y = np.vstack((labels[:i], labels[i+1:]))\n",
    "    X_hold_out = features[i].reshape(subset_size, feature_count)\n",
    "    y_hold_out = labels[i].reshape(subset_size, 1)\n",
    "    for j in range(subset_count-1):\n",
    "        X_train = np.vstack((X[:j], X[j+1:]))\n",
    "        X_train = X_train.reshape(train_set_size, feature_count)\n",
    "        y_train = np.vstack((y[:j], y[j+1:]))\n",
    "        y_train = y_train.reshape(train_set_size, 1)\n",
    "\n",
    "        X_test = X[j].reshape(subset_size, feature_count)\n",
    "        y_test = y[j].reshape(subset_size, 1)\n",
    "\n",
    "        param_err_RLS = np.zeros(len(lambda_vals))\n",
    "        w_hat_lst = []\n",
    "        \n",
    "        for idx, lmd in enumerate(lambda_vals):\n",
    "            w_hat = la.inv(X_train.T@X_train + lmd*np.identity(feature_count))\n",
    "            w_hat_lst.append(w_hat)\n",
    "            y_hat = X_test@w_hat\n",
    "\n",
    "            for s in range(subset_size):\n",
    "                if y_hat[s][0] <= 0 and y_test[s] == 1:\n",
    "                    param_err_RLS[idx] += 1\n",
    "                if y_hat[j][0] >= 0 and y_test[s] == -1:\n",
    "                    param_err_RLS[idx] += 1\n",
    "\n",
    "        k_best = np.argmin(param_err_RLS)\n",
    "        w_hat_best = w_hat_lst[k_best]\n",
    "\n",
    "        y_hat_hold_out = X_hold_out@w_hat_best\n",
    "        for z in range(subset_size):\n",
    "            if y_hat_hold_out[z][0] <= 0 and y_hold_out[z] == 1:\n",
    "                error_RLS[i][j] += 1\n",
    "            if y_hat_hold_out[z][0] >= 0 and y_hold_out[z] == -1:\n",
    "                error_RLS[i][j] += 1\n",
    "error_RLS = error_RLS/16\n",
    "print(f\"Error estimate: {np.mean(error_RLS)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
